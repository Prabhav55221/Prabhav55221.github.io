---
layout: page
permalink: /publications/index.html
title: Publications
---

> (†: equal contribution, ~: corresponding author)

## Conference Papers

- <span style="color: mediumpurple">[Count Your Speakers! Multitask Learning for Multimodal Speaker Diarization](https://Prabhav55221.github.io/file/CYS_MYD_CameraReady.pdf)</span><br>**Prabhav Singh~**, Jesus Villalba, Najim Dehak<br>In Proceedings of INTERSPEECH 2025<br>Rotterdam, Netherlands. August, 2025.<br><span style="color: red">Accepted [Presenting in August 2025]</span>

- <span style="color: mediumpurple">[EmoJudge: LLM Based Post-Hoc Refinement for Multimodal Speech Emotion Recognition](https://Prabhav55221.github.io/file/EmoJudge_Interspeech_CameraReady.pdf)</span><br>**Prabhav Singh~**, Jesus Villalba<br>In Proceedings of INTERSPEECH 2025<br>Rotterdam, Netherlands. August, 2025.<br><span style="color: red">Accepted [Presenting in August 2025]</span>

- <span style="color: mediumpurple">[Multimodal Emotion Recognition Harnessing the Complementarity of Speech,
Language, and Vision](https://dl.acm.org/doi/10.1145/3678957.3689332)</span><br>Thomas Thebaud†**~**, Anna Favaro†, **Prabhav Singh**†, Yaohan Guan†, Yuchen Yang†, Jesus Villalba, Laureano Mono-Velazquez, Najim Dehak<br>In Proc. of the 26th International Conference on Multimodal Interaction (ICMI ’24)<br>San Jose, Costa Rica. September, 2024.<br><span style="color: red"> First Position, Empathic Virtual Agent Challenge 2024</span>

## Peer-Reviewed Journals

- <span style="color: mediumpurple">[SEMI-FND: Stacked ensemble based multimodal inferencing framework for faster fake news detection](https://doi.org/10.1016/j.eswa.2022.119302)</span><br>**Prabhav Singh~**†, R. Srivastava†, K. Rana, V. Kumar<br>*Expert Systems With Applications*, Elsevier, Volume 215, 2023, Article 119302.<br>

- <span style="color: mediumpurple">[A topic modeled unsupervised approach to single document extractive text summarization](https://doi.org/10.1016/j.knosys.2022.108636)</span><br>R. Srivastava **~**†, **Prabhav Singh**†, K. Rana, V. Kumar<br>*Knowledge-Based Systems*, Elsevier, Volume 246, 2022, Article 108636.<br>

- <span style="color: mediumpurple">[A multimodal hierarchical approach to speech emotion recognition from audio and text](https://doi.org/10.1016/j.knosys.2021.107316)</span><br>**Prabhav Singh~**†, R. Srivastava†, K. Rana, V. Kumar<br>*Knowledge-Based Systems*, Elsevier, Volume 229, 2021, Article 107316.<br>

<br>


---

## Posters / Preprints / Challenges

> *Includes stuff I did for classes at JHU*

- <span style="color: mediumpurple">[Active Learning and Feature-Acquisition with LLMs and Humans](https://Prabhav55221.github.io/file/MASCSLL-FINAL.pdf)</span><br>**Prabhav Singh**, Haojun Shi, Jason Eisner<br>Mid-Atlantic Student Colloquium on Speech, Language and Learning 2025<br><span style="color: red"> Best Poster Award</span>

- <span style="color: mediumpurple">[The JHU-MIT Submission to NIST 2024 Speaker Recognition Evaluation
(SRE24)](https://Prabhav55221.github.io/file/nistsre.pdf)</span><br>Jesus Villalba, **Prabhav Singh**, J. Borgstrom et al.<br>National Institute of Science and Technology, Speech Recognition Evaluation 2024<br><span style="color: red">Accepted and Presented</span>

  <br>

---

<br>