---
layout: page
permalink: /publications/index.html
title: Publications
---

> (†: equal contribution, ~: corresponding author)

## Conference Papers

- <a href="https://www.arxiv.org/abs/2508.04901" style="color:#db3e75; font-weight:bold">Sensitivity of Stability: Theoretical & Empirical Analysis of Replicability for Adaptive Data Selection in Transfer Learning</a><br>
  **Prabhav Singh~**, Jessica Sorrell<br>
  Under Review at TMLR,<br>
  Available as arXiv preprint.<br>

- <a href="https://Prabhav55221.github.io/file/2025286331.pdf" style="color:#db3e75; font-weight:bold">The JHU-MIT System for NIST SRE24: Post-Evaluation Analysis</a><br>
  Jesus Villalba, Jonas Borgstron, **Prabhav Singh~** et al.<br>
  IEEE Automatic Speech Recognition and Understanding Workshop<br>
  ASRU 2025.<br>
  <span style="color: red">Accepted</span>

- <a href="https://www.isca-archive.org/interspeech_2025/singh25_interspeech.html" style="color:#db3e75; font-weight:bold">Count Your Speakers! Multitask Learning for Multimodal Speaker Diarization</a><br>
  **Prabhav Singh~**, Jesus Villalba, Najim Dehak<br>
  In Proceedings of INTERSPEECH 2025<br>
  Rotterdam, Netherlands. August, 2025.<br>
  <span style="color: red">Oral, Top 20%</span>

- <a href="https://www.isca-archive.org/interspeech_2025/singh25b_interspeech.html" style="color:#db3e75; font-weight:bold">EmoJudge: LLM Based Post-Hoc Refinement for Multimodal Speech Emotion Recognition</a><br>
  **Prabhav Singh~**, Jesus Villalba<br>
  In Proceedings of INTERSPEECH 2025<br>
  Rotterdam, Netherlands. August, 2025.<br>

- <a href="https://dl.acm.org/doi/10.1145/3678957.3689332" style="color:#db3e75; font-weight:bold">Multimodal Emotion Recognition Harnessing the Complementarity of Speech, Language, and Vision</a><br>
  Thomas Thebaud†**~**, Anna Favaro†, **Prabhav Singh**†, Yaohan Guan†, Yuchen Yang†, Jesus Villalba, Laureano Mono-Velazquez, Najim Dehak<br>
  In Proc. of the 26th International Conference on Multimodal Interaction (ICMI ’24)<br>
  San Jose, Costa Rica. September, 2024.<br>
  <span style="color: red"> First Position, Empathic Virtual Agent Challenge 2024</span>

## Peer-Reviewed Journals

- <a href="https://doi.org/10.1016/j.eswa.2022.119302" style="color:#db3e75; font-weight:bold">SEMI-FND: Stacked ensemble based multimodal inferencing framework for faster fake news detection</a><br>
  **Prabhav Singh~**†, R. Srivastava†, K. Rana, V. Kumar<br>
  *Expert Systems With Applications*, Elsevier, Volume 215, 2023, Article 119302.

- <a href="https://doi.org/10.1016/j.knosys.2022.108636" style="color:#db3e75; font-weight:bold">A topic modeled unsupervised approach to single document extractive text summarization</a><br>
  R. Srivastava **~**†, **Prabhav Singh**†, K. Rana, V. Kumar<br>
  *Knowledge-Based Systems*, Elsevier, Volume 246, 2022, Article 108636.

- <a href="https://doi.org/10.1016/j.knosys.2021.107316" style="color:#db3e75; font-weight:bold">A multimodal hierarchical approach to speech emotion recognition from audio and text</a><br>
  **Prabhav Singh~**†, R. Srivastava†, K. Rana, V. Kumar<br>
  *Knowledge-Based Systems*, Elsevier, Volume 229, 2021, Article 107316.

<br>

---

## Posters / Preprints / Challenges

> *Includes stuff I did for classes at JHU*

- <a href="https://Prabhav55221.github.io/marformer" style="color:#db3e75; font-weight:bold">Marformer: A Transformer for Predicting Missing Data Distributions</a><br>
  **Prabhav Singh**, Haojun Shi, Xiheng Wang, Jason Eisner<br>
  Center for Language and Speech Processing, Johns Hopkins University<br>
  <span style="color: red">Under Review</span>

- <a href="https://Prabhav55221.github.io/logical" style="color:#db3e75; font-weight:bold">When LLMs Know They Don't: Probing Latent Representations for Logical Insufficiency</a><br>
  Matt Wang†, **Prabhav Singh**†, Tom Wang†<br>
  Center for Language and Speech Processing, Johns Hopkins University<br>
  <span style="color: red">Class Project</span>

- <a href="https://Prabhav55221.github.io/file/nistsre.pdf" style="color:#db3e75; font-weight:bold">The JHU-MIT Submission to NIST 2024 Speaker Recognition Evaluation (SRE24)</a><br>
  Jesus Villalba, **Prabhav Singh**, J. Borgstrom et al.<br>
  National Institute of Science and Technology, Speech Recognition Evaluation 2024<br>
  <span style="color: red">Accepted and Presented</span>

- <a href="https://Prabhav55221.github.io/file/MASCSLL-FINAL.pdf" style="color:#db3e75; font-weight:bold">Active Learning and Feature-Acquisition with LLMs and Humans</a><br>
  **Prabhav Singh**, Haojun Shi, Jason Eisner<br>
  Mid-Atlantic Student Colloquium on Speech, Language and Learning 2025<br>
  <span style="color: red"> Best Poster Award</span>

<br>

---
